import os
import torch
import tempfile
import soundfile as sf
from datasets import load_dataset

from openvoice import se_extractor
from openvoice.api import ToneColorConverter

# Cáº¥u hÃ¬nh
ckpt_converter = 'checkpoints_v2/converter'
device = "cuda:0" if torch.cuda.is_available() else "cpu"
output_dir = 'outputs_v2'
embedding_name = 'vi-default'

os.makedirs(output_dir, exist_ok=True)
os.makedirs('checkpoints_v2/base_speakers/ses', exist_ok=True)

# Khá»Ÿi táº¡o converter
tone_color_converter = ToneColorConverter(f'{ckpt_converter}/config.json', device=device)
tone_color_converter.load_ckpt(f'{ckpt_converter}/checkpoint.pth')

# Táº£i dataset dáº¡ng stream tá»« Hugging Face
dataset = load_dataset("capleaf/viVoice", split="train", streaming=True)

# Sá»‘ lÆ°á»£ng audio máº«u Ä‘á»ƒ trÃ­ch xuáº¥t (tÃ¹y chá»‰nh theo nhu cáº§u)
max_samples = 100000

print(f"â³ Äang xá»­ lÃ½ tá»‘i Ä‘a {max_samples} máº«u tá»« dataset viVoice...")

all_embeddings = []
for i, example in enumerate(dataset):
    if i >= max_samples:
        break

    duration = len(example["audio"]["array"]) / example["audio"]["sampling_rate"]
    if duration < 3.0:
        print(f"   â­ Bá» qua máº«u quÃ¡ ngáº¯n ({duration:.2f} giÃ¢y)")
        continue
    
    print(f"ðŸ”Š Máº«u {i + 1}")

    try:
        # Ghi táº¡m file audio ra Ä‘Ä©a (báº¯t buá»™c vÃ¬ openvoice dÃ¹ng file path)
        with tempfile.NamedTemporaryFile(suffix=".wav", delete=False) as tmp_wav:
            sf.write(tmp_wav.name, example["audio"]["array"], example["audio"]["sampling_rate"])

            # TrÃ­ch xuáº¥t speaker embedding
            embedding, _ = se_extractor.get_se(tmp_wav.name, tone_color_converter, vad=True)
            all_embeddings.append(embedding)
            print("   âœ” ÄÃ£ trÃ­ch xuáº¥t embedding")

    except Exception as e:
        print(f"   âŒ Lá»—i khi xá»­ lÃ½: {e}")

# Trung bÃ¬nh vÃ  lÆ°u embedding
if all_embeddings:
    avg_embedding = torch.mean(torch.stack(all_embeddings), dim=0)
    save_path = f'checkpoints_v2/base_speakers/ses/{embedding_name}.pth'
    torch.save(avg_embedding, save_path)
    print(f"âœ… ÄÃ£ lÆ°u embedding táº¡i: {save_path}")
else:
    print("âŒ KhÃ´ng cÃ³ embedding nÃ o Ä‘Æ°á»£c táº¡o.")
